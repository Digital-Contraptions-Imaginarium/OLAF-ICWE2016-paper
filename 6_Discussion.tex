\section{Discussion}

[REFERENCE \cite{Gottlieb:2012fh} SIMILAR GI CROWDSOURCING CHALLENGES WITH OPEN ENDED TASK]

\subsection{CrowdFlower limitations in running iterative workflows}

Relying fully on CrowdFlower's and Google Map's cloud resources, without implementing an original front-end system, likely gave us the most cost-effective scalable and highly available solution to run the crowdsourcing campaign. This was not optimal, though, for the few reasons described below. 

\textbf{Finalised rows} When a CrowdFlower job is launched, the Requester specifies the target number of judgements for each item, or "row". Once the target numbers of judgements is collected, rows are marked as "finalized" in the system. If, later, the Requester increases the target number of judgements, collection does not re-start in any case for the finalised rows. This means that the only way to collect more judgements for finalised rows is to add them to the system again, as if they were new. Among the drawbacks, it can happen that the same Worker is assigned to judge the same row again. We address this by considering only the first judgement per Worker per road in the results.

\textbf{Partial test questions} It is not possible in CrowdFlower to specify "partial" test question such as the one we implemented asking the Workers to write again the street name as part of the survey. Test questions can only be complete, including all "columns" being subject to data collection. This means that we cannot *****  

\textbf{Worker white/black-listing} It is not possible to specify whitelists or blacklists of Workers. Only CrowdFlower can exclude a Worker from keeping contributing to a job and its results based on lack of sufficient accuracy against test questions. This means that the Requester has no means to blacklist a Worker if she is assessed to be inaccurate "outside" of CrowdFlower. We addressed this by assessing accuracy outside of CrowdFlower only and dropping all judgements made by the Workers who did not scored sufficiently. Unfortunately this also means that inaccurate Workers kept working and being paid.

\textbf{Dynamic reward} [NOT SURE THIS IS RELEVANT BUT DID NOT WANT TO FORGET ABOUT IT] Assuming higher compensation attracts a larger base of Workers to a task, and that a larger base of Workers generates judgements faster than a narrower one, one could use different rewards to accelerate the process by which judgements are collected.

[NOTE ABOUT THE OPPORTUNITY TO MANAGE HOW THE RESULTS NATURALLY CLUSTER AROUND A FEW HIGHEST HOUSE NUMBERS, AS WORKERS MAY MISS SOME PARTS OF THE ROAD, THIS SHOULD BE DISCUSSED IF IT HAPPENS OFTEN, AFTER OBSERVING LARGER VOLUMES OF SUBMISSIONS]